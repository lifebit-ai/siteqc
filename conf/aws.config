/*
 * -------------------------------------------------
 *  siteqc Nextflow base config file
 * -------------------------------------------------
 * A 'blank slate' config file, appropriate for general
 * use on most high performace compute environments.
 * Assumes that all software is installed and available
 * on the PATH. Runs in `local` mode - all jobs will be
 * run on the logged in environment.
 */


docker.enabled = true

params {

  // Workflow flags
  outdir = './results'
  publish_dir_mode = 'copy'

  // Files
  empty_file = 's3://lifebit-featured-datasets/projects/gel/siteqc/nodata'

  input = false
  xx_sample_ids = false
  xy_sample_ids = false
  triofile = false
  included_samples = false
  updfile = empty_file
  triodata_keep_pheno = empty_file
  triodata_fam = empty_file
  s3_path_1kg_start = 's3://1000genomes/release/20130502/ALL.'
  s3_path_1kg_end = '.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz'
  mend_err_p3_keep_fam = empty_file

  // Values
  king='T'
  query_format_start = '%CHROM %POS %REF %ALT %INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC\n'
  query_format_miss1 = '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC [%GT ] \n'
  query_include_miss1 = 'GT="./." & FORMAT/DP=0'
  query_format_miss2 = '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC [%GT ] \n'
  query_exclude_miss2 = 'GT~"\\."'
  query_exclude_median_gq = 'GT~"\\."'
  query_exclude_med_cov_nonmiss =  'GT~"\\."'
  query_format_med_cov_all = '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC [ %DP]\n'
  awk_expr_med_cov_all = '{sum=0; n=split(\$0,a)-1; for(i=2;i<=n;i++) sum+=a[i]; asort(a); median=n%2?a[n/2+1]:(a[n/2]+a[n/2+1])/2; print \$1"\t"median}' 
  query_format_med_cov_nonmisss = '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC [ %DP]\n'
  awk_expr_med_cov_nonmiss = '{sum=0; n=split(\$0,a)-1; for(i=2;i<=n;i++) sum+=a[i]; asort(a); median=n%2?a[n/2+1]:(a[n/2]+a[n/2+1])/2; print \$1"\t"median}'
  query_format_median_gq = '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC [%GQ ] \n'
  awk_expr_median_gq = '{sum=0; n=split(\$0,a)-1; for(i=2;i<=n;i++) sum+=a[i]; asort(a); median=n%2?a[n/2+1]:(a[n/2]+a[n/2+1])/2; if(median > 99) {median=99}; print \$1"\t"median}'
  query_format_ab_ratio_p1 = '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC [%AD ] \n'
  query_include_ab_ratio_1 = 'GT="het" & binom(FMT/AD) > 0.01'
  query_format_ab_ratio_p2 = '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC [%AD ] \n'
  query_include_ab_ratio_2 =  'GT="het"'
  query_format_pull_ac = '%CHROM:%POS-%REF/%ALT-%INFO/OLD_CLUMPED-%INFO/OLD_MULTIALLELIC %INFO/AC \n'
  awk_expr_miss1 = 'BEGIN{FS=" "} {print $1" "NF-1}'
  awk_expr_miss2 = 'BEGIN{FS=" "} {print $1" "NF-1}'
  awk_expr_ab_ratio_1 = '{print $1"\t"NF -1}'
  awk_expr_pull_1kg_p3_sites = '/^##/ {next} { print $1"\t"$2"\t"$4"\t"$5}'
  mend_err_p1_rset_missing_var_ids = '@:#,\\\$r,\\\$a'
  mend_err_p1_vcf_half_call = 'm'
  mend_err_p1_new_id_max_allele_len = '60 missing'

  //Custom resource definition
  cpus_per_process = 1
  memory_per_process = 2.GB
  cpus_mend_err_p1 = 4
  memory_mend_err_p1 = 32.GB
}


process {

  cpus = { check_max( params.cpus_per_process * task.attempt, 'cpus' ) }
  memory = { check_max( params.memory_per_process * task.attempt, 'memory' ) }
  time = { check_max( 4.h * task.attempt, 'time' ) }
  container = 'lifebitai/siteqc:1.0dev'
  errorStrategy = { task.exitStatus in [143,137,104,134,139] ? 'retry' : 'terminate' }

  // The most resource-heavy process
  withName: mend_err_p1 {
          cpus = { check_max( params.cpus_mend_err_p1 * task.attempt, 'cpus' ) }
          memory = { check_max( params.memory_mend_err_p1 * task.attempt, 'memory' ) }
  }
  
  executor = 'awsbatch'
  maxForks = 90 // keep below 100 max docker pulls limit 100 per 6h

}

aws.batch.cliPath = '/home/ec2-user/miniconda/bin/aws'
aws.batch.fetchInstanceType = true

aws {
  client {
    maxErrorRetry = 3000
    uploadMaxAttempts = 3000
    uploadRetrySleep = '10 sec'
  }
}

